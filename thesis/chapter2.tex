\chapter{Использование методов машинного обучения в системах управления с прогнозирующей моделью }

\section{Основные понятия нейронных сетей}

Нейронная сеть представляет собой серию алгоритмов, которые стремятся распознать базовые отношения в наборе данных посредством процесса, который имитирует работу человеческого мозга.

Нейронная сеть основана на наборе связанных единиц или узлов, называемых искусственными нейронами, которые свободно моделируют нейроны в биологическом мозге. Каждое соединение, подобно синапсам в биологическом мозге, может передавать сигнал от одного искусственного нейрона к другому. Искусственный нейрон, который получает сигнал, может обрабатывать его, а затем сигнализировать дополнительные искусственные нейроны, связанные с ним.

В общих реализациях нейронных сетей сигнал при соединении между искусственными нейронами является действительным числом, а выход каждого искусственного нейрона вычисляется некоторой нелинейной функцией от суммы его входов. Связи между искусственными нейронами называются ребрами. Искусственные нейроны и ребра обычно имеют вес, который регулируется по мере продолжения обучения. Вес увеличивает или уменьшает силу сигнала при соединении. Искусственные нейроны могут иметь такой порог, что сигнал посылается только тогда, когда совокупный сигнал пересекает этот порог. Как правило, искусственные нейроны агрегируются в слои. Различные слои могут выполнять различные виды преобразований на своих входах. Сигналы перемещаются от первого уровня (входного уровня) к последнему слою (выходному слою), возможно, после пересечения слоев несколько раз.

Ключевой моделью глубокого обучения являются нейронные сети с прямым распространением (многослойные персептроны). Целью данного вида нейронных сетей является аппроксимация некоторой функции $f^*$. Например, для классификатора $y = f^*(x)$ сеть отображает вход $x$ в категорию $y$. Сеть определяет отображение $y = f(x; \theta)$ и изучает значение параметров $\theta$, которые приводят к приближению функции наилучшим образом.

\begin{figure}[h]
\center{\includegraphics[scale=0.7]{neural_networks}}
\caption{Нейронная сеть со скрытыми слоями.}
\label{fig:nn}
\end{figure}

Нейронные сети называются сетями, потому что они обычно представляются объединением многих различных функций. Модель связана с ориентированным ациклическим графом (Рис. \ref{fig:nn}), описывающим, как функции состоят вместе. Например, мы могли бы иметь три функции $f^{(1)}$, $f^{(2)}$ и $f^{(3)}$, связанные в цепочке, с образованием $f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$. Эти цепные структуры являются наиболее часто используемыми структурами нейронных сетей. В этом случае $f^{(1)}$ называется первым слоем сети, $f^{(2)}$ называется вторым слоем и т. д. Длина цепочки слоев называется глубиной сети.

Каждый скрытый уровень сети обычно является векторным. Размерность этих скрытых слоев определяет ширину модели. Каждый элемент вектора может быть интерпретирован как играющий роль, аналогичную нейрону. Вместо того, чтобы думать о том, что слой представляет собой единую вектор-векторную функцию, мы также можем думать о том, что этот слой состоит из множества единиц, которые действуют параллельно, каждый из которых представляет собой вектор-скалярную функцию. Каждый блок напоминает нейрон в том смысле, что он получает вход от многих других единиц и вычисляет его собственное значение активации. 

\begin{figure}[h]
\center{\includegraphics[scale=0.7]{one_neuron}}
\caption{Строение нейрона.}
\label{fig:one_neuron}
\end{figure}

Нейрон обычно получает много одновременных входов. Каждый вход имеет свой собственный относительный вес, который дает входное воздействие, которое ему необходимо для функции суммирования элемента обработки. Эти веса выполняют тот же тип функции, что и различные синаптические силы биологических нейронов. В обоих случаях некоторые входы становятся более важными, чем другие, так что они оказывают большее влияние на обрабатывающий элемент, поскольку они объединяются для создания нейронного ответа. Веса - это адаптивные коэффициенты в сети, которые определяют интенсивность входного сигнала, зарегистрированного искусственным нейроном. Они являются мерой прочности соединения входа. Эти сильные стороны могут быть изменены в ответ на различные обучающие наборы и в соответствии с конкретной топологией сети или с помощью ее правил обучения.На рисунке (\ref{fig:one_neuron}) веса обозначены $w_i$, значения нейронов предыдущего слоя - $a_i$. $b$ параметр представляет собой смещение для линейного преобразования входных нейронов. Таким образом, мы получаем значение функции суммирования в виде линейного преобразования $z = b + \sum_{i=1}^{N}a_iw_i$.

Функция $g$ на рисунке (\ref{fig:one_neuron}) - это функция активации нейрона.  Цель использования функции активации заключается в том, чтобы позволить суммируемому результату меняться в зависимости от времени.Функцией по умолчанию является выпрямленная линейная активационная функция ReLU $g(x) = max(0,x)$,которая рекомендованна для использования с большинством нейронных сетей прямого распространения. Применение этой функции к выходу линейного преобразования приводит к нелинейному преобразованию. Однако функция остается очень близкой к линейной, в том смысле, что это кусочно-линейная функция с двумя линейными частями. Поскольку выпрямленные линейные единицы почти линейны, они сохраняют многие свойства, которые упрощают оптимизацию линейных моделей с помощью методов, основанных на градиенте. Другими популярными видами функции активации являются сигмоидальная(логистическая) функция $\sigma(x)=\frac{1}{1+e^{-x}}$, гиперболический тангенс $tanh(x) = \frac{e^x -e^{-x}}{e^x + e^{-x}}$.

Существует несколько видов обучения нейронных сетей:
\begin{itemize}
\item Обучение с учителем
\item Обучение без учителя
\end{itemize}

Подавляющее большинство искусственных нейронных сетевых решений проходят обучение с учителем. В этом режиме фактический выход нейронной сети сравнивается с желаемым выходом. Веса, которые обычно начинаются с произвольного начала, затем корректируются сетью, так что следующая итерация или цикл приведут к более близкому совпадению между желаемым и фактическим выходом. Метод обучения пытается минимизировать текущие ошибки всех элементов обработки. Это глобальное сокращение ошибок создается со временем, постоянно изменяя весы ввода до тех пор, пока не будет достигнута приемлемая точность сети.
При контролируемом обучении искусственная нейронная сеть должна быть обучена, прежде чем она станет полезна. Обучение состоит в представлении входных и выходных данных в сеть. Эти данные часто упоминаются как набор тренировок. То есть для каждого набора входных данных, предоставляемого системе, также предусмотрен соответствующий желаемый выходной набор. В большинстве приложений должны использоваться фактические данные. Эта стадия обучения может потреблять много времени. Затем используя метрики для расчета точности и качества модели, происходит процесс тренировки сети. Когда процесс тренировки заканчивается, то уже в online процессах используются эти натренированные параметры и веса. Некоторые типы сетей позволяют проводить непрерывную тренировку с гораздо меньшей скоростью во время работы. Это помогает сети адаптироваться к постепенно меняющимся условиям.

Сети без учителя не используют внешние воздействия для корректировки своих весов. Вместо этого они внутренне контролируют свою работу. Эти сети ищут закономерности или тенденции во входных сигналах и делают адаптацию в соответствии с функцией сети. Хотя и сеть обучается сама, необходимо специализировать, как сети огранизовать себя. Эта информация встроена в сетевую топологию и правила обучения.

Алгоритм обучения - алгорим обратного распространения ошибки, в котором используется стохастический градиентный спуск. Для задачи регресии чаще всего в качестве функции потерь используется средняя квадратичная ошибка(MSE)(\ref{loss_function}): 
\begin{equation}\label{loss_function}
L(y,y_{true}) = \frac{1}{N}\sum_{i=1}^N(y(i) -y_{true}(i))^2
\end{equation}

Согласно универсальной теореме аппроксимации — нейронная сеть с одним скрытым слоем может аппроксимировать любую непрерывную функцию многих переменных с любой точностью. Главное чтобы в этой сети было достаточное количество нейронов. И еще важно удачно подобрать начальные значения весов нейронов. Чем удачнее будут подобраны веса, тем быстрее нейронная сеть будет сходиться к исходной функции. Это означает, что нелинейная характеристика нейрона может быть произвольной: от сигмоидальной до произвольного волнового пакета или вейвлета, синуса или многочлена. От выбора нелинейной функции может зависеть сложность конкретной сети, но с любой нелинейностью сеть остаётся универсальным аппроксиматором и при правильном выборе структуры может достаточно точно аппроксимировать функционирование любой непрерывной функции.

\section{Методы обучения c подкреплением}

Обучение с подкреплением (RL) - это область машинного обучения, связанная с тем, как агенты программного обеспечения должны предпринимать действия в среде, чтобы максимизировать некоторое понятие кумулятивной награды. В литературе по исследованиям и контролю операций обучение с подкреплением называется приближенным динамическим программированием или нейродинамическим программированием. Проблемы интереса к обучению подкреплению изучались также в теории оптимального управления, которая в основном связана с существованием и характеристикой оптимальных решений, алгоритмами их точного вычисления или аппроксимацией, особенно в отсутствие математической модели среды.

В машинном обучении среда обычно формулируется как процесс принятия решений Маркова (MDP), так как многие алгоритмы обучения подкрепления для этого контекста используют методы динамического программирования. Основное различие между классическими методами динамического программирования и алгоритмами обучения усилению заключается в том, что последние не предполагают знания точной математической модели MDP и нацеливаются на большие MDP, где точные методы становятся неосуществимыми. [2] [1]

Усиление обучения отличается от стандартного контролируемого обучения тем, что правильные пары ввода / вывода не нуждаются в разъяснении, а субоптимальные действия не должны быть явно исправлены. Вместо этого основное внимание уделяется эффективности [необходимости уточнения], которая предполагает поиск баланса между разведкой (неизведанной территории) и эксплуатацией (существующих знаний) [4]. Компромисс в области разведки и эксплуатации был наиболее тщательно изучен в рамках многорукой бандитской проблемы и в конечных МДП.


\section{Методы машинного обучения в системах управления с прогнозирующей моделью}

Существует несколько подходов использования методов обучения в MPC системах:
\begin{itemize}
\item Аппроксимация закона управления 
\item Использование обучаемой модели для аппроксимации динамики прогнозирующей модели
\item Итерационный подход для построения терминального региона и функции из предыдущих итераций
\end{itemize}

\section{Аппроксимация закона управления}
\section{Аппроксимация динамики системы с прогнозирующей моделью}
\section{Итерационный подход}
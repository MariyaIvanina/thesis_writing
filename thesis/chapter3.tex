\chapter{Построение нейросетевого регулятора}

\section{Постановка задачи}
Рассмотрим нелинейную дискретную динамическую систему
\begin{equation} \label{general_task}
x(t+1) = f(x(t), u(t)),
\end{equation} 
где $x(t) \in \mathbb{R}^n$ - вектор состояний, $u(t) \in \mathbb{R}^m$ - вектор управления и $f(0,0) = 0$. Мы рассматриваем ограничения вида 
\begin{equation}
X = \left \{  x \in \mathbb{R}^n | Hx \leq 1_p \right \}, \ U = \left \{ u \in \mathbb{R}^m | Lu \leq 1_q \right \}
\end{equation}


Также необходимо, чтобы выполнялось ограничение 
\begin{equation}
x(t), u(t)) \in X \times U \ \forall t \geq 0.
\end{equation} 

Будем оптимизировать функцию стоимости
\begin{equation}
min_{u(\cdot|t)} \sum_{k=0}^{N-1}l(x,u) + V_f(X(N)).
\end{equation}

Исследования будут проводиться на примере из  \cite{ParisiniZoppoli}.

Нелинейная система в дискретном виде представляет собой

\begin{equation}
x(t+1)_1 = x(t)_1 + \delta( -x(t)_2 + 0.5(1+ x(t)_1)u(t))
\end{equation}
\begin{equation*}
x(t+1)_2 = x(t)_2 + \delta( x(t)_1 + 0.5(1 - 4x(t)_2)u(t))
\end{equation*}
с ограничениями
\begin{equation*}
x \in X = \{-1 \leq x_1 \leq 0.5, \ -1 \leq x_2 \leq 1.5\}
\end{equation*}
\begin{equation*}
u \in U = \{-1 \leq u \leq 1\}
\end{equation*}

Шаг дискретизации $\delta = 0.1$. Данная система имеет стабилизируемое первое приближение в начале координат, которое имеет вид
\begin{equation*}
x(t+1) = Ax(t) + Bu,  \ \ A = \begin{bmatrix}
   1 & -0.05 \\
    0.05 & 1
\end{bmatrix}, \ B = \begin{bmatrix}
   0.025 \\
    0.025
\end{bmatrix}.
\end{equation*}

Линейный локальный закон управления для терминального множества представляет собой $k_f(x(t)) = Kx(t) = \begin{bmatrix}
0.3799, & -0.4201
\end{bmatrix}x(t)$.

Параметры для терминального множества и функции посчитаны с помощью алгоритмов квази-бесконечного MPC из первой главы. Для данной системы функция качества имеет вид

\begin{equation}
V(x(t)) = \min_{u(\cdot|t)} \sum_{k=0}^{N-1}(||u(k|t)||^2 + 0.1||x(k|t)||^2) + V_f(x(t))
\end{equation}

где 
\begin{equation*}
V_f(x(t)) = x(t)^TPx(t) = x(t)^T\begin{bmatrix}
   48.3043 & -2.53 \\
    -2.53 & 70.8191
\end{bmatrix}x(t).
\end{equation*}

Терминальное множество задается в виде эллипсоида 
$$X_f = \{x \in \mathbb{R}^n | x(t)^TPx \leq \alpha\},$$
где $\alpha = 0.2129$. Таким образом, для системы определены все дизайн параметры для проведения процедуры MPC алгоритма. 
 
\section{Подход к решению}

Алгоритм MPC для стабилизации положения равновесия $x=0$ системы (\ref{general_task}) состоит в следующем:
Для каждого $t = 0, 1, \ldots$ \\
1. измерить состояние $x(t) \in X$ системы (1);\\
2. решить задачу (3) с начальным условием $x(0|t) = x(t)$, получить $u^0 (\cdot|t)$;\\
3. подать на вход системы (1) управляющее воздействие $u_{MPC}(x(t)):=u^0(0|t)$.

При выполнении ряда требований к функциям $l$, $V_f$ и множеству $X_f$ замкнутая система 
$$
    x(t+1) = f(x(t), u_{MPC}(x(t))), \ \ t=0,1, \ldots,
    $$
асимптотически устойчива с областью притяжения $X_0 = \{x_0: V(x_0)<+\infty\}\subseteq X$, состоящей из всех точек $x_0\in X$, для которых задача ${\cal P}(x_0)$ имеет решение [1, 2]. В первой главе приводится простой способ построения квадратичных функций $l$, $V_f$ и эллипсоида $X_f$, удовлетворяющих упомянутым условиям.

Как отмечено выше, шаг 2 приведенного алгоритма может оказаться достаточно трудоемким. В связи с этим в настоящей работе предлагается вместо онлайн решения прогнозирующей задачи численными методами оптимального управления использовать  до начала процесса управления ряд методов машинного обучения, которые на основе обучающей выборки $(x, u_{MPC}(x))\in X\times U$ будут строить приближенные значения $\bar u_{MPC}(x(t))$ обратной связи $u_{MPC}(x)$, $x\in X$, для текущих состояний $x(t)$.

В настоящей работе применяются метод опорных векторов (Support Vector Machine, SVM) и нейронные сети. Метод опорных векторов с  радиальной базисной функции Гаусса \cite{Chakrabarty} используется, во-первых,  для выделения и аппроксимации области притяжения $X_0$ системы (\ref{general_task}). Это позволяет эффективно обрабатывать текущие состояния динамической системы и не допускать выход за пределы области притяжения при управлении с помощью приближенных обратных связей.  Во-вторых, метод опорных векторов применяется для многоклассовой классификации с целью выделения областей насыщения управления.  Наконец, в областях, в которых обратная связь $u_{MPC}$ принимает промежуточные значения, она аппроксимируется с использованием нейронной сети.

Обучение нейронной сети и классификация на основе SVM дает приближенное управления типа обратной связи $\bar u_{MPC}(x)$, $x\in X_0$. Система, замкнутая обратной связью $\bar u_{MPC}(x)$, $x\in X_0$, имеет вид
$$
    x (t + 1) = f (x (t), \bar u_{MPC}(x (t))), \ \ t = 0, 1, \ldots. \eqno(4)
    $$

В работе с использованием результатов \cite{Pin} исследуются условия, при которых, несмотря на ошибки аппроксимации, гарантируется выполнение ограничений  и асимптотическая устойчивость замкнутой системы. Кроме того, проводится сравнение приближенных законов управления, обученных на равномерной сетке, на сетке, полученной на основе равномерно распределенных последовательностей, и на случайной сетке с увеличением объема обучающей выборки в окрестности положения равновесия.

%Для этого подхода необходимо вычислить значения управления в каждой точке сетки состояний для допустимых значений состояний. Далее обучается сеть на этих значениях,как задача обучения с учителем. Основные недостатки данного подхода:
%\begin{itemize}
%\item Необходимо брать достаточно много точек для хорошей аппроксимации, хотя иногда некоторые области имеют одинаковые значения и для них не надо вычислять заново управление
%\item Обучение и валидация проходят достаточно долго
%\end{itemize}

%Предполагаемые улучшения для этого подхода:
%\begin{itemize}
%\item Уменьшить кол-во генерируемых точек для гарантирования %аппроксимации
%\item Попробовать более точно вычислить $X_{feas}$ 
%\item Расспаралеллить получение точек и валидацию аппроксимированной функции нейронной сети
%\item Рассмотреть возможность использования обучение без учителя и обучение с подкреплением
%\end{itemize}  

\section{Базовая реализация нейросетевого регулятора}

Базовый вариант включает себя создание нейронной сети для аппроксимации $\bar u(t)$. Далее вычисляем для этих точек управление и следующее состояние из этой точки. На рисунке  \ref{fig:v_f} показано векторное поле этой сетки. Из каждой точки сетки можно увидеть куда эта точка перейдет. Горизонт планирования был взят $N=20$, т.е. мы планируем и высчитываем управления и состояния на $20$ шагов вперед. Относительно рисунка видно, что мы смогли из точки $(-0.7,-0.8)$ попасть достаточно близко к началу координат, однако если взять некоторые точки где следующее состояние выходит за рамки нашего обучения, то мы можем получить нестабильное решение.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{vector_field}}
\caption{Результаты базовой реализации.Векторное поле.}
\label{fig:v_f}
\end{figure}

Далее если посмотреть на рисунок \ref{fig:c_l}, то можно увидеть множество одинаковых управлений для состояний. Однако важно отметить, что сетка значений около начала координат должна быть достаточно детальной, чтобы не попасть в нестабильное положение управления.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{control_law}}
\caption{Вычисленное управление для сетки значений состояний для обучения нейронной сети}
\label{fig:c_l}
\end{figure}

Обучаемая нейронная сеть представляет сеть с одним скрытым слоем с $20$ нейронами. Впоследствии будет описана процедура поиска оптимальнаго количества нейронов, а также других параметров нейронной сети.
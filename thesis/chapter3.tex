\chapter{Построение нейросетевого регулятора}

\section{Постановка задачи}
Рассмотрим нелинейную дискретную динамическую систему
\begin{equation} \label{general_task}
x(t+1) = f(x(t), u(t)),
\end{equation} 
где $x(t) \in \mathbb{R}^n$ - вектор состояний, $u(t) \in \mathbb{R}^m$ - вектор управления и $f(0,0) = 0$. Мы рассматриваем ограничения вида 
\begin{equation}
X = \left \{  x \in \mathbb{R}^n | Hx \leq 1_p \right \}, \ U = \left \{ u \in \mathbb{R}^m | Lu \leq 1_q \right \}
\end{equation}


Также необходимо, чтобы выполнялось ограничение $(x(t), u(t)) \in X \times U \ \forall t \geq 0$. 

Будем оптимизировать функцию стоимости $min_{u(\cdot|t)} \sum_{k=0}^{N-1}l(x,u) + V_f(X(N))$
 
\section{Подход к решению}

MPC регулятор, построенный для задачи (\ref{general_task}), робастный по отношению к неточному управлению $u$ в пределах выбранных границ.RMPC дискретизируется по множеству допустимых состояний $X_{feas}$ и аппроксимируется с использованием нейронной сети, основанной на этих точках. Обучение дает апроксимированный MPC $ \pi_{feas} : X_{feas} \to U | u = \pi_{approx} (x)$. С этим регулятором система замкнутого контура задается как $x (t + 1) = f (x (t), \pi_{approx} (x (t)))$.  Стабильность замкнутого контура гарантируется, если погрешность аппроксимации ниже допустимой границы входного возмущения от робастного MPC. Используется метод проверки, основанный на неравенстве Хоэффинга, чтобы гарантировать эту оценку.

Для этого подхода необходимо вычислить значения управления в каждой точке сетки состояний для допустимых значений состояний. Далее обучается сеть на этих значениях,как задача обучения с учителем. Основные недостатки данного подхода:
\begin{itemize}
\item Необходимо брать достаточно много точек для хорошей аппроксимации, хотя иногда некоторые области имеют одинаковые значения и для них не надо вычислять заново управление
\item Обучение и валидация проходят достаточно долго
\end{itemize}

Предполагаемые улучшения для этого подхода:
\begin{itemize}
\item Уменьшить кол-во генерируемых точек для гарантирования аппроксимации
\item Попробовать более точно вычислить $X_{feas}$ 
\item Расспаралеллить получение точек и валидацию аппроксимированной функции нейронной сети
\item Рассмотреть возможность использования обучение без учителя и обучение с подкреплением
\end{itemize}  

\section{Результаты обучения нейронной сети для данной задачи. Базовая реализация}

Базовый вариант включает себя создание нейронной сети, которая обучается на состояниях $X = \{-1 \leq x_1 \leq 0.5, \ -1 \leq x_2 1.5\}$ и берутся точки этого множества с шагом $0.1$. Далее вычисляем для этих точек управление и следующее состояние из этой точки. На рисунке  \ref{fig:v_f} показано векторное поле этой сетки. Из каждой точки сетки можно увидеть куда эта точка перейдет. Горизонт планирования был взят $N=20$б т.е. мы планируем и высчитываем управления и состояния на $20$ шагов вперед. Относительно рисунка видно, что мы смогли из точки $(-0.7,-0.8)$ попасть достаточно близко к началу координат, однако если взять некоторые точки где следующее состояние выходит за рамки нашего обучения, то мы можем получить нестабильное решение.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{vector_field}}
\caption{Результаты базовой реализации.Векторное поле.}
\label{fig:v_f}
\end{figure}

Далее если посмотреть на рисунок \ref{fig:c_l}, то можно увидеть множество одинаковых управлений для состояний. Однако важно отметить, что сетка значений около начала координат должна быть достаточно детальной, чтобы не попасть в нестабильное положение управления.

\begin{figure}[h]
\center{\includegraphics[scale=0.3]{control_law}}
\caption{Вычисленное управление для сетки значений состояний для обучения нейронной сети}
\label{fig:c_l}
\end{figure}

Обучаемая нейронная сеть представляет сеть с одним скрытым слоем с $20$ нейронами. Впоследствии будет описана процедура поиска оптимальнаго количества нейронов, а также других параметров нейронной сети.